# Task B â€“ Face Recognition (FACECOM Challenge)

## ğŸ§  Objective
Develop a face recognition system that can match distorted or degraded face images to known identities using a Siamese Network.

---

## ğŸ“‚ Dataset Structure

Task_B/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 001_frontal/
â”‚   â”œâ”€â”€ 002_frontal/
â”‚   â””â”€â”€ ...          â† Each folder = one identity (e.g., person)
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ 001_frontal/
â”‚   â”œâ”€â”€ 009_frontal/
â”‚   â””â”€â”€ ...
â””â”€â”€ val_filtered/    â† Subset of `val/` where identities also exist in `train/`

- Each folder represents a unique identity.
- Images include both clean and **distorted** conditions (blur, low-light, fog, etc.).

---

## ğŸ”§ Methodology

### ğŸ“Œ Model Architecture
- **Siamese Network** using `ResNet18` as backbone
- Distance metric: **Cosine Similarity**
- Output: Embedding vector from final layer

### ğŸ’¡ Training Strategy
- Input: Positive & negative pairs
- Loss: `Contrastive Loss`
- Optimizer: Adam
- Epochs: 5

---

### ğŸ§  Siamese Model Architecture

![Siamese Model](model_diagram_manual.png)

---

## ğŸ§ª Evaluation Strategy

- Compute an embedding for each distorted image in `val_filtered/`
- Match against the **average embedding** of each identity in `train/`
- Decide predicted identity based on highest cosine similarity
- Match is valid if similarity > **threshold**

---

### ğŸ“Š Metrics Reported
- Accuracy
- Precision
- Recall
- F1-Score

---

### ğŸ—‚ Project Files (Important)

| File                     | Description                                               |
|--------------------------|-----------------------------------------------------------|
| `Task_B_Model.ipynb`     | ğŸ”§ Full training and evaluation pipeline                   |
| `test_Task_B.py`         | ğŸ§ª CLI script for evaluating pretrained model              |
| `val_results.csv`        | ğŸ“Š Evaluation results (can be renamed from best run)       |
| `model_diagram_manual.png` | ğŸ§  Siamese architecture diagram                         |
| `siamese_model.pth`      | ğŸ§  Trained Siamese model weights [(Download)](https://drive.google.com/uc?export=download&id=1VKhmhASUwyuoT7XNfIm_ARr1gI1H_iU9) |
| `train/`                 | ğŸ§‘â€ğŸ“ Reference identity folders (used at test time)        |
| `val_filtered/`          | ğŸ–¼ï¸ Distorted validation set (filtered identities only)     |

---

## â–¶ï¸ How to Run Evaluation

```bash
python test_Task_B.py --model_path siamese_model.pth --train_dir Task_B/train --val_dir Task_B/val_filtered --threshold 0.93
```

ğŸ’¡ On Linux/macOS, use `\\` for line continuation.

### ğŸ§¾ Parameters

| Argument       | Description                          |
|----------------|--------------------------------------|
| --model_path   | Path to `.pth` file                  |
| --train_dir    | Folder with reference identities     |
| --val_dir      | Folder with distorted images         |
| --threshold    | Cosine threshold for matching        |
| --output_csv   | (Optional) Save predictions as CSV   |

---

## ğŸ“¦ No Need to Retrain

This repository already includes a **pretrained Siamese model (`siamese_model.pth`)**.

âœ… You do **not** need to rerun training or use the original training set to test.

Just use `test_Task_B.py` with `val_filtered/` and the model file.

---

## ğŸ§ª Setup & Requirements

Ensure Python 3.8+ is installed.

Install dependencies:

```
pip install torch torchvision scikit-learn pandas tqdm matplotlib
```

Optional (for notebooks):

```
pip install notebook
```

---

## ğŸ“ˆ Evaluation Metrics

### ğŸ‹ï¸ During Training (val_filtered)
| Metric     | Value   |
|------------|---------|
| Accuracy   | 0.9716  |
| Precision  | 0.9738  |
| Recall     | 0.9712  |
| F1-Score   | 0.9719  |

### ğŸ§ª Final Testing via Script (threshold = 0.93)
| Metric     | Value   |
|------------|---------|
| Accuracy   | 0.7170  |
| Precision  | 0.3170  |
| Recall     | 1.0000  |
| F1-Score   | 0.4814  |

ğŸ“Œ **Note:** The higher training accuracy was obtained under clean/controlled validation.  
The script-based test reflects **realistic distorted faces**, where performance drops â€” this shows model robustness in tough conditions.

---

## âœ… Notes
- `val_filtered` only contains validation identities present in `train/`
- Code auto-skips non-image files and `.ipynb_checkpoints`

---

## ğŸ‘©â€ğŸ’» Authors
- **Srijani Saha**  
- **Shreyanka Roy**  
- Submission for **FACECOM Challenge 2025**

---

## âš ï¸ Important Submission Notes

- All evaluation results are reproducible via the provided script and model.
- No training is required during testing.
- â— Changing thresholds or retraining is not necessary unless explicitly allowed by organizers.
